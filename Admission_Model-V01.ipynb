{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import opendatasets as od\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:Your Kaggle Key:Dataset URL: https://www.kaggle.com/datasets/mohansacharya/graduate-admissions\n",
      "Downloading graduate-admissions.zip to .\\graduate-admissions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.64k/9.64k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "od.download('https://www.kaggle.com/datasets/mohansacharya/graduate-admissions/code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('graduate-admissions')\n",
    "\n",
    "df = pd.read_csv('graduate-admissions/Admission_Predict_Ver1.1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Research\n",
       "1    280\n",
       "0    220\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Research.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X,Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled= scaler.fit_transform(X_train)\n",
    "X_test_scaled= scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7, activation='relu', input_dim=7))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 15)                120       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 30)                480       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 687\n",
      "Trainable params: 687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "10/10 [==============================] - 1s 49ms/step - loss: 0.6210 - val_loss: 0.4839\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3796 - val_loss: 0.2776\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1960 - val_loss: 0.1225\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0694 - val_loss: 0.0313\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0152 - val_loss: 0.0114\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0146\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0123 - val_loss: 0.0111\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0095 - val_loss: 0.0107\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0094\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0092\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0090\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0087\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 0.0084\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0082\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0075\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0068 - val_loss: 0.0073\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0061 - val_loss: 0.0067\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0060 - val_loss: 0.0067\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0065\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0057 - val_loss: 0.0063\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.0035\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(X_train_scaled, Y_train, validation_split=0.2, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "pred= model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8262993954922379"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(Y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20b47936ad0>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
